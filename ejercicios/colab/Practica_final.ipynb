{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05KLsiM7EoFm",
    "colab_type": "text"
   },
   "source": [
    "#Objetivo de la práctica\n",
    "\n",
    "La práctica consiste en hacer una lista de palabras más 'asociadas' a otra en un fichero de texto. En concreto, veremos las palabras asociadas a 'man' y a 'woman' en la Biblia (hay gente que dice que es el libro que más ha influido en la cultura occidental: es el más vendido, junto con el Corán y el Libro Rojo de Mao).\n",
    "\n",
    "Cambiando constantes podréis hacer el mismo análisis con un fichero diferente y con palabras diferentes. Iremos paso a paso, con ejercicios intercalados.\n",
    "\n",
    "A la izquierda, en 'Archivos', tenéis que subir el fichero con el texto (si no véis un fichero que se llama 'bible.txt'). Lo podéis descargar con el navegador si le dáis 'botón derecho' sobre el siguiente enlace: http://www.gutenberg.org/ebooks/30.txt.utf-8 y le dáis a 'guardar enlace' como 'bible.txt'. Despúes, le dáis a 'subir' en la pestaña de Archivos de la izquierda, elegís 'bible.text', desde donde lo hayáis guardado en vuestro disco duro y aparecerá. Si no lo véis, dadle a 'Actualizar' en la misma caja. Entre sesión y sesión de trabajo os desaparecerá. Si os da un error intentando abrir el archivo, comprobad siempre si está subido para trabajar, aunque lo tengáis que volver a hacer. Es un poco tedioso, no sé por qué lo han hecho así...\n",
    "\n",
    "La lista de palabras la podéis usar en https://wordart.com/create para generar nubes de palabras o importarlas en Google Spreadsheets para analizarlas. Lo explico al final de la práctica, con los resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNZcm6cTIH3_",
    "colab_type": "text"
   },
   "source": [
    "#Carga del fichero\n",
    "\n",
    "Vamos a ver cómo cargar el fichero en una lista, directamente, con 'open', o 'cogiéndolo' via web. En esta sección se usan cadenas y listas, si quieres repasarlas, en https://colab.research.google.com/github/oscarmarinmiro/blanquerna_2018/blob/master/ejercicios/colab/00_Cadenas_y_funciones.ipynb y  https://colab.research.google.com/github/oscarmarinmiro/blanquerna_2018/blob/master/ejercicios/colab/01_Listas_For_y_While.ipynb hay ejercicios para practicar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILOT-aELIY-N",
    "colab_type": "text"
   },
   "source": [
    "## Carga del fichero con 'open'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "b29V6WmEIdtQ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Hay que asegurarse de que el fichero está subido a 'Archivos', como se explica\n",
    "# en el primer párrafo\n",
    "# Los ficheros los podemos abrir en modo lectura, para almacenarlos en variables\n",
    "# O en modo escritura, para hacer lo contrario: Almacenar el contenido del fichero\n",
    "# en una variable\n",
    "\n",
    "# Abrimos el fichero 'bible.txt, que existe en la pestaña 'Archivos' de la derecha\n",
    "# en modo lectura ('r')\n",
    "\n",
    "file_in = open(\"bible.txt\", \"r\")\n",
    "\n",
    "# Creamos una lista vacía\n",
    "\n",
    "file_lines = []\n",
    "\n",
    "# Leemos por líneas, quintando los caracteres que sobran de la derecha (retornos\n",
    "# de carro, etc..)\n",
    "\n",
    "for line in file_in:\n",
    "  # Insertamos la línea en la lista, quintando la 'morralla' con con rstrip \n",
    "  # (https://python-reference.readthedocs.io/en/latest/docs/str/rstrip.html)\n",
    "  file_lines.append(line.rstrip())\n",
    "  \n",
    "# Imprimimos las 500 primeras líneas para comprobar lo que hemos hecho.\n",
    "# OJO!!! No imprimir todas las líneas porque este entorno tiene límites en la\n",
    "# cantidad de líneas que se pueden imprimit\n",
    "\n",
    "for line in file_lines[:100]:\n",
    "  print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fICTYkXSKrBi",
    "colab_type": "text"
   },
   "source": [
    "##Carga del fichero desde la web (con la librería requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "aVZ3VttVK4Mk",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# En la clase de API's vimos como descargar páginas web y acceder a API's\n",
    "# con la librería requests (http://docs.python-requests.org/en/master/)\n",
    "# Únicamente vamos a acceder a una dirección web del proyecto Gutemberg donde está\n",
    "# Alojado este texto y descargarlo\n",
    "\n",
    "# Importamos la librería, no forma parte de la distribución estándar\n",
    "\n",
    "import requests\n",
    "\n",
    "# Con requests.get descargamos cualquier página web\n",
    "\n",
    "my_request = requests.get('http://www.gutenberg.org/ebooks/30.txt.utf-8')\n",
    "\n",
    "# En my_request tenemos el resultado de la descarga, accedemos al texto descargado\n",
    "# con my_request.text\n",
    "\n",
    "my_text = my_request.text\n",
    "\n",
    "# Imprimimos lo 1000 primeros caracteres para comprobar la descarga\n",
    "\n",
    "print(my_text[:1000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ZZ5Zg68ELttp",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "my_request = requests.get('http://www.gutenberg.org/ebooks/30.txt.utf-8')\n",
    "\n",
    "my_text = my_request.text\n",
    "\n",
    "\n",
    "# Vamos a usar la variable 'my_text' para 'partir' el texto en líneas.\n",
    "# No podemos recorrer el texto como una lista,\n",
    "# como hacíamos en el caso de la carga directa con 'open'\n",
    "\n",
    "# Declaramos una lista vacía para rellenarla con líneas\n",
    "\n",
    "file_lines = []\n",
    "\n",
    "# Lo que tenemos que hacer es 'partir' el texto entero por el carácter '\\n', que \n",
    "# siempre representa un cambio de línea en los ficheros de texto. Esto lo hace\n",
    "# por nosotros Python cuando leemos un fichero de texto vía 'open', pero no en\n",
    "# este caso\n",
    "\n",
    "# Con 'split', transformamos una cadena (como es este texto entero) en una lista,\n",
    "# 'partiendo' su contenido por un carácter, en este caso el retorno de carro o '\\n'\n",
    "\n",
    "my_lines = my_text.split(\"\\n\")\n",
    "\n",
    "# Ahora recorremos las lineas y quitamos la 'morralla' de la derecha, como hacíamos\n",
    "# en el caso del fichero directo\n",
    "\n",
    "for line in my_lines:\n",
    "  file_lines.append(line.rstrip())\n",
    "  \n",
    " # Y comprobamos las 100 primeras líneas\n",
    "\n",
    "for line in file_lines[:100]:\n",
    "  print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxiiyjuKOx29",
    "colab_type": "text"
   },
   "source": [
    "##Ejercicio número 1\n",
    "\n",
    "Sabiendo que en la lista 'file_lines' tenemos el texto, línea a línea, escribir debajo el código para imprimir el contenido de las líneas 100 a la 200, usando 'slices', como en las dos últimas líneas del ejemplo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Q5HJSCYHOuo9",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# EJERCICIO 1\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "my_request = requests.get('http://www.gutenberg.org/ebooks/30.txt.utf-8')\n",
    "\n",
    "my_text = my_request.text\n",
    "\n",
    "\n",
    "# Vamos a usar la variable 'my_text' para 'partir' el texto en líneas.\n",
    "# No podemos recorrer el texto como una lista,\n",
    "# como hacíamos en el caso de la carga directa con 'open'\n",
    "\n",
    "# Declaramos una lista vacía para rellenarla con líneas\n",
    "\n",
    "file_lines = []\n",
    "\n",
    "my_lines = my_text.split(\"\\n\")\n",
    "\n",
    "for line in my_lines:\n",
    "  file_lines.append(line.rstrip())\n",
    "\n",
    "\n",
    "# TÚ CÓDIGO AQUÍ\n",
    "# ...\n",
    "# TÚ CÓDIGO AQUÍ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSDcCpM4S39v",
    "colab_type": "text"
   },
   "source": [
    "#Conteo de apariciones de una palabra\n",
    "\n",
    "Vamos a empezar por contar el número de líneas en las que aparece una determinada palabra en todo el texto.\n",
    "Recorreremos todas las líneas, comprobando una a una si aparece la palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "E-Th1zLgTjRE",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "my_request = requests.get('http://www.gutenberg.org/ebooks/30.txt.utf-8')\n",
    "\n",
    "my_text = my_request.text\n",
    "\n",
    "file_lines = []\n",
    "\n",
    "my_lines = my_text.split(\"\\n\")\n",
    "\n",
    "for line in my_lines:\n",
    "  file_lines.append(line.rstrip())\n",
    "\n",
    "# Vamos a contar el número de líneas en las que aparece la palabra 'woman' \n",
    "\n",
    "# Usamos 'count' para mantener la cuenta y lo ponemos a 'cero' al inicio\n",
    "\n",
    "count = 0\n",
    "\n",
    "for line in file_lines:\n",
    "  # usamos la versión en minúsculas de la línea, con 'line.lower()'\n",
    "  if 'woman' in line.lower():\n",
    "    count+=1\n",
    "\n",
    "print(\"WOMAN ha aparecido en\", count, \"líneas de\", len(file_lines))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SP1NSwYkU87U",
    "colab_type": "text"
   },
   "source": [
    "##Ejercicio número 2\n",
    "\n",
    "Cambiar el código anterior para que podamos contar el número de líneas en las que aparezca cualquier palabra.\n",
    "Para ello, declararemos una variable para almacenar la palabra que queremos buscar. Hay que completar el resto de líneas debajo para que nos imprima bien el resultado. Probarlo con la palabra 'man' y la palabra 'woman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "_cNmY1MVVejL",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "my_request = requests.get('http://www.gutenberg.org/ebooks/30.txt.utf-8')\n",
    "\n",
    "my_text = my_request.text\n",
    "\n",
    "file_lines = []\n",
    "\n",
    "my_lines = my_text.split(\"\\n\")\n",
    "\n",
    "for line in my_lines:\n",
    "  file_lines.append(line.rstrip())\n",
    "\n",
    "\n",
    "# Vamos a contar el número de líneas en las que aparece la palabra almacenada en\n",
    "# la variable word\n",
    "\n",
    "word = \"woman\"\n",
    "\n",
    "# Usamos 'count' para mantener la cuenta y lo ponemos a 'cero' al inicio\n",
    "\n",
    "count = 0\n",
    "\n",
    "# TU CÓDIGO AQUÍ DEBAJO, muy parecido al de la caja de código anterior\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_x6mF30YWAkc",
    "colab_type": "text"
   },
   "source": [
    "#Conteo de las palabras que aparecen en la misma línea que la palabra que hemos elegido\n",
    "\n",
    "Si elegimos, por ejemplo, la palabra 'woman', lo que queremos saber es qué palabras se usan más frecuentemente en las líneas en las que aparece 'woman'. Vamos a ir paso a paso viendo todo lo que necesitamos hacer. En esta sección se usan diccioanrios, si quieres repasarlos, hay ejercicios en https://colab.research.google.com/github/oscarmarinmiro/blanquerna_2018/blob/master/ejercicios/colab/02_Diccionarios.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSbpP9ZtWfQ8",
    "colab_type": "text"
   },
   "source": [
    "## Conocer todas las palabras de una línea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "H4U9y-hPWeAZ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Si tenemos esta cadena:\n",
    "\n",
    "cadena = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\"\n",
    "\n",
    "# Podemos 'trocearla' en palabras usando la función 'split', como hemos usado\n",
    "# para 'partir' el texto en líneas cuando lo cogíamos de la web.\n",
    "# En nuestro caso, podemos partir por 'espacios', así:\n",
    "\n",
    "palabras = cadena.split(\" \")\n",
    "\n",
    "# Imprimimos este primer intento:\n",
    "\n",
    "print(\"PRIMER INTENTO\")\n",
    "\n",
    "for palabra in palabras:\n",
    "  print(palabra)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "X1JyIiQpYleg",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "cadena = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\"\n",
    "\n",
    "\n",
    "# Como vemos, al no tener en cuenta las comas y los puntos, hay palabras 'contaminadas' por los puntos y las comas, como 'amet', 'elit' y 'aliqua'.\n",
    "# Para solucionarlo, vamos a reemplazar todos estos caracteres por 'espacios' y luego partir por espacios\n",
    "# Usamos la función 'replace', que sustituye todas las apariciones de un carácter por otro. Podemos ejecutar varios\n",
    "# 'replace', llamándolos uno detrás de otro. También sustituimos los dobles espacios por los simples\n",
    "\n",
    "cadena = cadena.replace(\",\", \" \").replace(\".\", \" \").replace(\"  \", \" \")\n",
    "\n",
    "print(\"La cadena traducida es: \", cadena)\n",
    "\n",
    "palabras = cadena.split(\" \")  \n",
    "\n",
    "print (\"SEGUNDO INTENTO\")\n",
    "\n",
    "for palabra in palabras:\n",
    "  print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "P9Apzi4-ZLqr",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Ahora lo haremos de una manera un poco más elegante, vamos a definir una lista\n",
    "# con todos los separadores y recorrerla cuando hagamos los replace. Nos quedaremos\n",
    "# con esta maneraa\n",
    "\n",
    "cadena = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\"\n",
    "\n",
    "separadores = [\";\", \",\", \".\", \":\", \"''\", \"?\", \"  \"]\n",
    "\n",
    "for separador in separadores:\n",
    "  cadena = cadena.replace(separador, \" \")\n",
    "  \n",
    "palabras = cadena.split(\" \")\n",
    "\n",
    "print(\"ÚLTIMO INTENTO\")\n",
    "\n",
    "for palabra in palabras:\n",
    "  print(palabra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVAKCxalZ_QX",
    "colab_type": "text"
   },
   "source": [
    "##Contar frecuencias de palabras y ordenar el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "wcWgeIywaIpK",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# Ya sabemos sacar la lista de palabras que aparecen en una línea, el resultado \n",
    "# es una lista. Lo que necesitamos ahora es un diccionario para mantener la cuenta\n",
    "# de cuántas veces ha aparecido una palabra.\n",
    "\n",
    "# Usamos un lorem ipsum de prueba más largo que el anterior\n",
    "# (es una sola línea, porque no lleva retornos de carro ['\\n'])\n",
    "\n",
    "lorem_text = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"\n",
    "\n",
    "separadores = [\";\", \",\", \".\", \":\", \"''\", \"?\", \"  \"]\n",
    "\n",
    "# Pasamos el texto a minúsculas, para que 'Lorem' y 'lorem' cuenten como una misma\n",
    "# palabra\n",
    "\n",
    "lorem_text = lorem_text.lower()\n",
    "\n",
    "# Traducimos los separadores a espacios\n",
    "\n",
    "for separador in separadores:\n",
    "  lorem_text = lorem_text.replace(separador, \" \")\n",
    "  \n",
    "palabras = lorem_text.split(\" \")  \n",
    "\n",
    "# Inicializamos un diccionario vacío\n",
    "\n",
    "diccionario_palabras = {}\n",
    "\n",
    "# Imprimimos las palabras al tiempo que actualizamos el diccionario\n",
    "\n",
    "print(\"LISTA DE PALABRAS, CON ALGUNA REPETIDA\")\n",
    "\n",
    "# Para cada palabra en la lista de palabras\n",
    "\n",
    "for palabra in palabras:\n",
    "  \n",
    "  # Comprobamos si la palabra no está en el diccionario\n",
    "  # Si no existe, hay que insertarlo (la clave del diccionario es la palabra)\n",
    "  # Y almacenar un '1' (el valor del diccionario es cuántas veces ha aparecido)\n",
    "  \n",
    "  if palabra not in diccionario_palabras:\n",
    "    diccionario_palabras[palabra] = 1    \n",
    "    \n",
    "  # Si la palabra ya existe, hay que sumar 1 a la cuenta almacenada para esa palabra\n",
    "  \n",
    "  else:\n",
    "    diccionario_palabras[palabra] = diccionario_palabras[palabra] + 1\n",
    "    \n",
    "  print(palabra)\n",
    "  \n",
    "# Imprimimos el diccionario\n",
    "\n",
    "print(\"DICCIONARIO DE PALABRAS Y SU CONTEO\")\n",
    "\n",
    "for palabra in diccionario_palabras.keys():\n",
    "  print(palabra, \"-->\", diccionario_palabras[palabra])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3ESIwhYi-7O",
    "colab_type": "text"
   },
   "source": [
    "## Ejercicio número 3\n",
    "\n",
    "Sabiendo que en diccionario_palabras tenemos un diccionario con clave cada palabra y contenido el conteo, recorrer el diccionario y sólamente imprimir las palabras que tienen una cuenta mayor que 2. Os dejo el esqueleto en el código de abajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "5bWsfOJFja2C",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "lorem_text = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"\n",
    "\n",
    "separadores = [\";\", \",\", \".\", \":\", \"''\", \"?\", \"  \"]\n",
    "\n",
    "# Pasamos el texto a minúsculas, para que 'Lorem' y 'lorem' cuenten como una misma\n",
    "# palabra\n",
    "\n",
    "lorem_text = lorem_text.lower()\n",
    "\n",
    "# Traducimos los separadores a espacios\n",
    "\n",
    "for separador in separadores:\n",
    "  lorem_text = lorem_text.replace(separador, \" \")\n",
    "  \n",
    "palabras = lorem_text.split(\" \")  \n",
    "\n",
    "# Inicializamos un diccionario vacío\n",
    "\n",
    "diccionario_palabras = {}\n",
    "\n",
    "# Para cada palabra en la lista de palabras\n",
    "\n",
    "for palabra in palabras:\n",
    "  \n",
    "  # Comprobamos si la palabra no está en el diccionario\n",
    "  # Si no existe, hay que insertarlo (la clave del diccionario es la palabra)\n",
    "  # Y almacenar un '1' (el valor del diccionario es cuántas veces ha aparecido)\n",
    "  \n",
    "  if palabra not in diccionario_palabras:\n",
    "    diccionario_palabras[palabra] = 1    \n",
    "    \n",
    "  # Si la palabra ya existe, hay que sumar 1 a la cuenta almacenada para esa palabra\n",
    "  \n",
    "  else:\n",
    "    diccionario_palabras[palabra] = diccionario_palabras[palabra] + 1\n",
    "     \n",
    "\n",
    "# TU CÓDIGO AQUÍ (HAY QUE INSPIRARSE EN LAS DOS ÚLTIMAS LÍNEAS DEL CÓDIGO ANTERIOR)\n",
    "# ...\n",
    "# TU CÓDIGO AQUÍ\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hHjG-GjkW4P",
    "colab_type": "text"
   },
   "source": [
    "##Ordenado de un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "xdgUzNg2c6DU",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "lorem_text = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"\n",
    "\n",
    "separadores = [\";\", \",\", \".\", \":\", \"''\", \"?\", \"  \"]\n",
    "\n",
    "lorem_text = lorem_text.lower()\n",
    "\n",
    "for separador in separadores:\n",
    "  lorem_text = lorem_text.replace(separador, \" \")\n",
    "  \n",
    "palabras = lorem_text.split(\" \")  \n",
    "diccionario_palabras = {}\n",
    "\n",
    "for palabra in palabras:\n",
    "  if palabra not in diccionario_palabras:\n",
    "    diccionario_palabras[palabra] = 1    \n",
    "  else:\n",
    "    diccionario_palabras[palabra] = diccionario_palabras[palabra] + 1\n",
    "\n",
    "\n",
    "# Ya tenemos las palabras en un diccionario, ahora lo que queremos hacer \n",
    "# es ordenar las palabras por su frecuencia: Vamos a sacar las 5 más frecuentes\n",
    "\n",
    "\n",
    "# Función que, pasada una palabra, devuelve el conteo de la misma,\n",
    "# buscando en el diccionario que hemos construido arriba\n",
    "\n",
    "def conteo(palabra):\n",
    "  return diccionario_palabras[palabra]\n",
    "\n",
    "# Esta línea de abajo ordena las claves de un diccionario por su cuenta, usando la función\n",
    "# conteo de arriba. reverse = True significa que queremos las que tienen más conteo primero\n",
    "\n",
    "# SI NO LO ENTENDÉIS, NO OS PREOCUPÉIS: está fuera de lo que hemos enseñado, pero\n",
    "# lo necesitamos para la práctica.\n",
    "\n",
    "# Lo importante es que os construye una lista \n",
    "# con las palabras ordenas de mayor a menor conteo\n",
    "\n",
    "ordenadas = sorted(diccionario_palabras.keys(), key = conteo, reverse = True)\n",
    "\n",
    "# Ahora nos quedamos con las 5 primeras\n",
    "\n",
    "ordenadas = ordenadas[:5]\n",
    "\n",
    "# Imprimimos sus frecuencias\n",
    "\n",
    "for palabra in ordenadas:\n",
    "  print(palabra, \"-->\", diccionario_palabras[palabra])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVgf_PI0e42l",
    "colab_type": "text"
   },
   "source": [
    "## Eliminar palabras frecuentes para quedarnos con las importantes\n",
    "\n",
    "En el ejemplo anterior, vemos que las más frecuentes son palabras como conjunciones, pronombres, etc... Lo habitual es definir una lista de palabras 'demasiado frecuentes' que no queremos contar porque siempre aparecen en el lenguaje. Para esto, vamos a definir una lista de palabras que llamaremos 'stopwords' y no las insertaremos en el diccionario de conteo si aparecen. Abajo os pongo un ejemplo de como quedaría un conteo de palabras en una frase cogida de la Biblia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "uSuFn9-FfhSc",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# Estas stopwords son las 205 palabras más frecuentes en la Biblia\n",
    "\n",
    "stopwords = ['the', 'and', 'that', 'shall', 'unto', 'for', 'his', 'lord', 'they', 'him', 'not', 'them', 'with', 'all',\n",
    "             'thou', 'thy', 'was', 'god', 'which', 'said', 'but', 'their', 'have', 'will', 'thee', 'from', 'are',\n",
    "             'when', 'this', 'were', 'out', 'upon', 'man', 'you', 'israel', 'king', 'son', 'there', 'hath', 'then',\n",
    "             'people', 'came', 'had', 'house', 'into', 'her', 'come', 'one', 'children', 'before', 'your', 'also',\n",
    "             'day', 'land', 'men', 'against', 'shalt', 'let', 'hand', 'saying', 'made', 'went', 'even', 'now', 'behold',\n",
    "             'saith', 'therefore', 'every', 'these', 'because', 'after', 'our', 'things', 'father', 'down', 'sons',\n",
    "             'hast', 'david', 'make', 'say', 'may', 'over', 'did', 'what', 'jesus', 'earth', 'she', 'who', 'great',\n",
    "             'name', 'any', 'thine', 'away', 'among', 'put', 'thereof', 'forth', 'give', 'neither', 'take', 'days',\n",
    "             'city', 'brought', 'moses', 'two', 'heart', 'pass', 'judah', 'jerusalem', 'according', 'should', 'know',\n",
    "             'whom', 'nor', 'took', 'thus', 'bring', 'offering', 'good', 'place', 'set', 'word', 'more', 'sent', 'yet',\n",
    "             'again', 'like', 'way', 'eat', 'mine', 'heard', 'about', 'called', 'time', 'evil', 'holy', 'egypt', 'see',\n",
    "             'own', 'hundred', 'spake', 'heaven', 'christ', 'done', 'brethren', 'many', 'hear', 'fire', 'saw',\n",
    "             'fathers', 'how', 'priest', 'words', 'thing', 'years', 'himself', 'law', 'thousand', 'speak', 'spirit',\n",
    "             'voice', 'off', 'eyes', 'cast', 'given', 'servant', 'art', 'answered', 'three', 'than', 'together',\n",
    "             'servants', 'other', 'might', 'ever', 'work', 'those', 'gave', 'through', 'seven', 'hands', 'soul',\n",
    "             'another', 'would', 'life', 'cities', 'blood', 'sin', 'commanded', 'side', 'without', 'first', 'peace',\n",
    "             'sword', 'mouth', 'saul', 'flesh', 'face', 'gold', 'high', 'whose', 'can', 'both', 'yea', 'where']\n",
    "\n",
    "separadores = [\";\", \",\", \".\", \":\", \"''\", \"?\", \"  \"]\n",
    "\n",
    "frase = \"These are the generations of Shem: Shem was an hundred years old, and begat Arphaxad two years after the flood: And Shem lived after he begat Arphaxad five hundred years, and begat sons and daughters.\"\n",
    "\n",
    "# Traducimos los separadores a espacios\n",
    "\n",
    "for separador in separadores:\n",
    "  frase = frase.replace(separador, \" \")\n",
    "  \n",
    "# Partimos en palabras la versión en minúscula de la frase\n",
    "\n",
    "palabras = frase.lower().split(\" \")  \n",
    "\n",
    "# Inicializamos un diccionario vacío\n",
    "\n",
    "frecuencias = {}\n",
    "\n",
    "# Para cada palabra\n",
    "\n",
    "for palabra in palabras:\n",
    "  \n",
    "  # Si no está en stopwords, mide más de 2 y no es un número, actualizamos\n",
    "  # diccionario\n",
    "  \n",
    "  if palabra not in stopwords and len(palabra)>2 and not palabra.isdigit():\n",
    "    if palabra not in frecuencias:\n",
    "      frecuencias[palabra] = 1\n",
    "    else:\n",
    "      frecuencias[palabra] = frecuencias[palabra] + 1\n",
    "      \n",
    "print(\"El diccionario de frecuencias es:\\n\")\n",
    "\n",
    "pprint.pprint(frecuencias)\n",
    "\n",
    "# Ordenamos y nos quedamos con las cinco primeras\n",
    "\n",
    "def conteo(palabra):\n",
    "  return frecuencias[palabra]\n",
    "\n",
    "ordenadas = sorted(frecuencias.keys(), key = conteo, reverse = True)[:5]\n",
    "\n",
    "print(\"\\nLas cinco palabras más frecuentes, ordenadas: \")\n",
    "\n",
    "for palabra in ordenadas:\n",
    "  print(palabra, \"-->\", frecuencias[palabra])\n",
    "\n",
    "      \n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89PfwhiqiG-k",
    "colab_type": "text"
   },
   "source": [
    "#El código final y dos ejercicios\n",
    "\n",
    "Debajo está el código final para imprimir las palabras más asociadas a otra, combinando los resultados de los ejercicios anteriores. Os propongo dos ejercicios después.\n",
    "\n",
    "Fijáos que cambiando la variable PALABRA podemos analizar cualquier palabra, y cambiando FICHERO podemos analizar cualquier fichero que hayamos subido (aunque quizá haya que cambiar las STOPWORDS, que son específicas de la Biblia, son las 200 más frecuentes).\n",
    "\n",
    "IMPORTANTE: Si os da un error abriendo el fichero, comprobad siempre que lo tenéis subido a 'Archivos', en la pestaña a la izquierda de esta caja. Si no está ahí, podéis seguir las instrucciones del primer párrafo de la práctica para subirlo.\n",
    "\n",
    "Si copiáis lo que imprime el código, tal cual viene, lo podéis pegar en https://wordart.com/create, en la opción de 'words/import', pegándolo en la caja y marcando la opción 'import as csv' y dándole a 'Visualize'. Sí, las nubes de palabras mucha gente las detesta y no las recomienda, pero creo que es una manera de que veáis algo tangible de vuestro trabajo. En 'FONTS' podéis cambiar la fuente y en 'SHAPES' podéis hacer que la nube siga una determinada forma. Lo podéis descargar en .jpg y .png.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "zj8znHT-k2gJ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# CONSTANTES\n",
    "\n",
    "STOPWORDS = ['the', 'and', 'that', 'shall', 'unto', 'for', 'his', 'lord', 'they', 'him', 'not', 'them', 'with', 'all',\n",
    "             'thou', 'thy', 'was', 'god', 'which', 'said', 'but', 'their', 'have', 'will', 'thee', 'from', 'are',\n",
    "             'when', 'this', 'were', 'out', 'upon', 'man', 'you', 'israel', 'king', 'son', 'there', 'hath', 'then',\n",
    "             'people', 'came', 'had', 'house', 'into', 'her', 'come', 'one', 'children', 'before', 'your', 'also',\n",
    "             'day', 'land', 'men', 'against', 'shalt', 'let', 'hand', 'saying', 'made', 'went', 'even', 'now', 'behold',\n",
    "             'saith', 'therefore', 'every', 'these', 'because', 'after', 'our', 'things', 'father', 'down', 'sons',\n",
    "             'hast', 'david', 'make', 'say', 'may', 'over', 'did', 'what', 'jesus', 'earth', 'she', 'who', 'great',\n",
    "             'name', 'any', 'thine', 'away', 'among', 'put', 'thereof', 'forth', 'give', 'neither', 'take', 'days',\n",
    "             'city', 'brought', 'moses', 'two', 'heart', 'pass', 'judah', 'jerusalem', 'according', 'should', 'know',\n",
    "             'whom', 'nor', 'took', 'thus', 'bring', 'offering', 'good', 'place', 'set', 'word', 'more', 'sent', 'yet',\n",
    "             'again', 'like', 'way', 'eat', 'mine', 'heard', 'about', 'called', 'time', 'evil', 'holy', 'egypt', 'see',\n",
    "             'own', 'hundred', 'spake', 'heaven', 'christ', 'done', 'brethren', 'many', 'hear', 'fire', 'saw',\n",
    "             'fathers', 'how', 'priest', 'words', 'thing', 'years', 'himself', 'law', 'thousand', 'speak', 'spirit',\n",
    "             'voice', 'off', 'eyes', 'cast', 'given', 'servant', 'art', 'answered', 'three', 'than', 'together',\n",
    "             'servants', 'other', 'might', 'ever', 'work', 'those', 'gave', 'through', 'seven', 'hands', 'soul',\n",
    "             'another', 'would', 'life', 'cities', 'blood', 'sin', 'commanded', 'side', 'without', 'first', 'peace',\n",
    "             'sword', 'mouth', 'saul', 'flesh', 'face', 'gold', 'high', 'whose', 'can', 'both', 'yea', 'where']\n",
    "\n",
    "SEPARADORES = [\";\", \",\", \".\", \":\", \"'\", \"?\", \"  \"]\n",
    "\n",
    "TOP_WORDS = 50\n",
    "\n",
    "FICHERO = \"bible.txt\"\n",
    "\n",
    "PALABRA = \"man\"\n",
    "\n",
    "# CONSTANTES\n",
    "\n",
    "# Abrimos fichero\n",
    "\n",
    "file_in = open(FICHERO, \"r\")\n",
    "\n",
    "# Diccionario para almacenar las frecuencias\n",
    "\n",
    "word_dictionary = {}\n",
    "\n",
    "# Lo recorremos línea a línea\n",
    "\n",
    "for line in file_in:\n",
    "  \n",
    "  # A minúsculas y quitamos el ruido del final de la cadena\n",
    "  \n",
    "  line = line.lower().rstrip()\n",
    "  \n",
    "  # Si la palabra existe en la línea\n",
    "  \n",
    "  if PALABRA in line:\n",
    "    \n",
    "        # Traducimos separadores por espacios\n",
    "    \n",
    "        for separador in SEPARADORES:\n",
    "          line = line.replace(separador, \" \")\n",
    "          \n",
    "        # Partimos por espacioes\n",
    "          \n",
    "        words = line.split(\" \")\n",
    "        \n",
    "        # Para cada palabra\n",
    "\n",
    "        for word in words:\n",
    "            \n",
    "            # Si la palabra 'mide' más de 2, es distinta a la original, no está en stopwords y no es número\n",
    "            # Evitamos insertar la palabra original ('woman') en el diccionario, porque siempre saldría la primera\n",
    "            # y porque estamos analizando las que la 'acompañan'\n",
    "            \n",
    "            if len(word) > 2 and word != PALABRA and word not in STOPWORDS and not word.isdigit():\n",
    "              \n",
    "                # Actualizamos la cuenta en el diccionario\n",
    "                \n",
    "                if word not in word_dictionary:\n",
    "                    word_dictionary[word] = 0\n",
    "\n",
    "                word_dictionary[word] = word_dictionary[word] + 1\n",
    "                \n",
    "# Cogemos las 50 palabras más frecuentes, ordenadas por conteo\n",
    "                \n",
    "frequent_words = sorted(word_dictionary.keys(), key=lambda key: word_dictionary[key], reverse=True)[:TOP_WORDS]\n",
    "\n",
    "# Imprimimos las palabras más frecuentes y su conteo\n",
    "\n",
    "for word in frequent_words:\n",
    "    text = word + \";\" + str(word_dictionary[word])\n",
    "    print(text)\n",
    "\n",
    "                \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmNvOLco46B8",
    "colab_type": "text"
   },
   "source": [
    "##Ejercicio número 4\n",
    "\n",
    "Vamos a guardar a fichero las palabras más frecuentes, en formato 'csv', pero con separador ';'. Debajo tenéis un recordatorio de cómo podéis escribir a .csv, con unas líneas muy similares a las que tenéis que usar para el ejercicio, que está en la caja siguiente a la de abajo. Recordad que hay que subir el fichero si no está y que cuando lo escribáis, es posible que tengáis que darle a 'actualizar' en la caja de Archivos, para verlo y poder descargarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbSRa7uKeseu",
    "colab_type": "text"
   },
   "source": [
    "###Recordatorio de escritura a fichero csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "3h8lBWrp5c5U",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Vamos a escribir este diccionario a un fichero csv, sin cabecera, sólo los datos\n",
    "\n",
    "\n",
    "frecuencias = {\n",
    "    'hola': 15,\n",
    "    'adiós': 5,\n",
    "    'python': 10\n",
    "}\n",
    "\n",
    "file_out = open(\"frecuencias.csv\", \"w\")\n",
    "\n",
    "for palabra in frecuencias.keys():\n",
    "  text = palabra + \";\" + str(frecuencias[palabra])\n",
    "  file_out.write(text + \"\\n\")\n",
    "\n",
    "file_out.close()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZIUwKIUIFAc",
    "colab_type": "text"
   },
   "source": [
    "###Ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "LJjmH_Zh6X9x",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# EJERCICIO 4: Haciendo algo similar al código de la caja anterior, guardar a fichero csv el resultado de las palabras más frecuentes\n",
    "# Abajo tenéis el código completo copiado, y en las últimas tres líneas es donde tenéis\n",
    "# que añadir más líneas para, aparte de imprimir por pantalla las frecuencias, guardarlas a un fichero\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CONSTANTES\n",
    "\n",
    "STOPWORDS = ['the', 'and', 'that', 'shall', 'unto', 'for', 'his', 'lord', 'they', 'him', 'not', 'them', 'with', 'all',\n",
    "             'thou', 'thy', 'was', 'god', 'which', 'said', 'but', 'their', 'have', 'will', 'thee', 'from', 'are',\n",
    "             'when', 'this', 'were', 'out', 'upon', 'man', 'you', 'israel', 'king', 'son', 'there', 'hath', 'then',\n",
    "             'people', 'came', 'had', 'house', 'into', 'her', 'come', 'one', 'children', 'before', 'your', 'also',\n",
    "             'day', 'land', 'men', 'against', 'shalt', 'let', 'hand', 'saying', 'made', 'went', 'even', 'now', 'behold',\n",
    "             'saith', 'therefore', 'every', 'these', 'because', 'after', 'our', 'things', 'father', 'down', 'sons',\n",
    "             'hast', 'david', 'make', 'say', 'may', 'over', 'did', 'what', 'jesus', 'earth', 'she', 'who', 'great',\n",
    "             'name', 'any', 'thine', 'away', 'among', 'put', 'thereof', 'forth', 'give', 'neither', 'take', 'days',\n",
    "             'city', 'brought', 'moses', 'two', 'heart', 'pass', 'judah', 'jerusalem', 'according', 'should', 'know',\n",
    "             'whom', 'nor', 'took', 'thus', 'bring', 'offering', 'good', 'place', 'set', 'word', 'more', 'sent', 'yet',\n",
    "             'again', 'like', 'way', 'eat', 'mine', 'heard', 'about', 'called', 'time', 'evil', 'holy', 'egypt', 'see',\n",
    "             'own', 'hundred', 'spake', 'heaven', 'christ', 'done', 'brethren', 'many', 'hear', 'fire', 'saw',\n",
    "             'fathers', 'how', 'priest', 'words', 'thing', 'years', 'himself', 'law', 'thousand', 'speak', 'spirit',\n",
    "             'voice', 'off', 'eyes', 'cast', 'given', 'servant', 'art', 'answered', 'three', 'than', 'together',\n",
    "             'servants', 'other', 'might', 'ever', 'work', 'those', 'gave', 'through', 'seven', 'hands', 'soul',\n",
    "             'another', 'would', 'life', 'cities', 'blood', 'sin', 'commanded', 'side', 'without', 'first', 'peace',\n",
    "             'sword', 'mouth', 'saul', 'flesh', 'face', 'gold', 'high', 'whose', 'can', 'both', 'yea', 'where']\n",
    "\n",
    "SEPARADORES = [\";\", \",\", \".\", \":\", \"'\", \"?\", \"  \"]\n",
    "\n",
    "TOP_WORDS = 50\n",
    "\n",
    "FICHERO = \"bible.txt\"\n",
    "\n",
    "PALABRA = \"man\"\n",
    "\n",
    "# CONSTANTES\n",
    "\n",
    "# Abrimos fichero\n",
    "\n",
    "file_in = open(FICHERO, \"r\")\n",
    "\n",
    "# Diccionario para almacenar las frecuencias\n",
    "\n",
    "word_dictionary = {}\n",
    "\n",
    "# Lo recorremos línea a línea\n",
    "\n",
    "for line in file_in:\n",
    "  \n",
    "  # A minúsculas y quitamos el ruido del final de la cadena\n",
    "  \n",
    "  line = line.lower().rstrip()\n",
    "  \n",
    "  # Si la palabra existe en la línea\n",
    "  \n",
    "  if PALABRA in line:\n",
    "    \n",
    "        # Traducimos separadores por espacios\n",
    "    \n",
    "        for separador in SEPARADORES:\n",
    "          line = line.replace(separador, \" \")\n",
    "          \n",
    "        # Partimos por espacioes\n",
    "          \n",
    "        words = line.split(\" \")\n",
    "        \n",
    "        # Para cada palabra\n",
    "\n",
    "        for word in words:\n",
    "            \n",
    "            # Si la palabra 'mide' más de 2, es distinta a la original, no está en stopwords y no es número\n",
    "            # Evitamos insertar la palabra original ('woman') en el diccionario, porque siempre saldría la primera\n",
    "            # y porque estamos analizando las que la 'acompañan'\n",
    "            \n",
    "            if len(word) > 2 and word != PALABRA and word not in STOPWORDS and not word.isdigit():\n",
    "              \n",
    "                # Actualizamos la cuenta en el diccionario\n",
    "                \n",
    "                if word not in word_dictionary:\n",
    "                    word_dictionary[word] = 0\n",
    "\n",
    "                word_dictionary[word] = word_dictionary[word] + 1\n",
    "                \n",
    "# Cogemos las 50 palabras más frecuentes, ordenadas por conteo\n",
    "                \n",
    "frequent_words = sorted(word_dictionary.keys(), key=lambda key: word_dictionary[key], reverse=True)[:TOP_WORDS]\n",
    "\n",
    "# Imprimimos las palabras más frecuentes y su conteo\n",
    "\n",
    "# EJERCICIO 4: Aquí es dónde hay que añadir líneas para guardar a fichero\n",
    "# manteniendo las que hay, para que se siga imprimiendo\n",
    "\n",
    "for word in frequent_words:\n",
    "    text = word + \";\" + str(word_dictionary[word])\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEpKrMlc8NAf",
    "colab_type": "text"
   },
   "source": [
    "##Ejercicio número 5\n",
    "\n",
    "Vamos a sacar la inserción de palabras en el diccionario a una función a la que se le pasa una línea de texto y el diccionario, para que lo actualice con las palabras. Es el ejercicio más difícil. Abajo tenéis el código del ejercicio. Tenéis que rellenar la zona de código donde pone 'TU CÓDIGO AQUÍ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Ft2juKpR9XR8",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# EJERCICIO 5: Completar la función actualiza_diccionario\n",
    "\n",
    "\n",
    "# CONSTANTES\n",
    "\n",
    "STOPWORDS = ['the', 'and', 'that', 'shall', 'unto', 'for', 'his', 'lord', 'they', 'him', 'not', 'them', 'with', 'all',\n",
    "             'thou', 'thy', 'was', 'god', 'which', 'said', 'but', 'their', 'have', 'will', 'thee', 'from', 'are',\n",
    "             'when', 'this', 'were', 'out', 'upon', 'man', 'you', 'israel', 'king', 'son', 'there', 'hath', 'then',\n",
    "             'people', 'came', 'had', 'house', 'into', 'her', 'come', 'one', 'children', 'before', 'your', 'also',\n",
    "             'day', 'land', 'men', 'against', 'shalt', 'let', 'hand', 'saying', 'made', 'went', 'even', 'now', 'behold',\n",
    "             'saith', 'therefore', 'every', 'these', 'because', 'after', 'our', 'things', 'father', 'down', 'sons',\n",
    "             'hast', 'david', 'make', 'say', 'may', 'over', 'did', 'what', 'jesus', 'earth', 'she', 'who', 'great',\n",
    "             'name', 'any', 'thine', 'away', 'among', 'put', 'thereof', 'forth', 'give', 'neither', 'take', 'days',\n",
    "             'city', 'brought', 'moses', 'two', 'heart', 'pass', 'judah', 'jerusalem', 'according', 'should', 'know',\n",
    "             'whom', 'nor', 'took', 'thus', 'bring', 'offering', 'good', 'place', 'set', 'word', 'more', 'sent', 'yet',\n",
    "             'again', 'like', 'way', 'eat', 'mine', 'heard', 'about', 'called', 'time', 'evil', 'holy', 'egypt', 'see',\n",
    "             'own', 'hundred', 'spake', 'heaven', 'christ', 'done', 'brethren', 'many', 'hear', 'fire', 'saw',\n",
    "             'fathers', 'how', 'priest', 'words', 'thing', 'years', 'himself', 'law', 'thousand', 'speak', 'spirit',\n",
    "             'voice', 'off', 'eyes', 'cast', 'given', 'servant', 'art', 'answered', 'three', 'than', 'together',\n",
    "             'servants', 'other', 'might', 'ever', 'work', 'those', 'gave', 'through', 'seven', 'hands', 'soul',\n",
    "             'another', 'would', 'life', 'cities', 'blood', 'sin', 'commanded', 'side', 'without', 'first', 'peace',\n",
    "             'sword', 'mouth', 'saul', 'flesh', 'face', 'gold', 'high', 'whose', 'can', 'both', 'yea', 'where']\n",
    "\n",
    "SEPARADORES = [\";\", \",\", \".\", \":\", \"'\", \"?\", \"  \"]\n",
    "\n",
    "TOP_WORDS = 50\n",
    "\n",
    "FICHERO = \"bible.txt\"\n",
    "\n",
    "PALABRA = \"man\"\n",
    "\n",
    "# CONSTANTES\n",
    "\n",
    "def actualiza_diccionario(linea, diccionario):\n",
    "  \n",
    "  # Traducimos separadores por espacios\n",
    "  for separador in SEPARADORES:\n",
    "    \n",
    "    linea = linea.replace(separador, \" \")\n",
    "          \n",
    "    # Partimos por espacioes\n",
    "\n",
    "    words = line.split(\" \")\n",
    "\n",
    "    # Para cada palabra\n",
    "\n",
    "    for word in words:\n",
    "\n",
    "        # Si la palabra 'mide' más de 2, es distinta a la original, no está en stopwords y no es número\n",
    "        # Evitamos insertar la palabra original ('woman') en el diccionario, porque siempre saldría la primera\n",
    "        # y porque estamos analizando las que la 'acompañan'\n",
    "\n",
    "        if len(word) > 2 and word != PALABRA and word not in STOPWORDS and not word.isdigit():\n",
    "\n",
    "            # Actualizamos la cuenta en el diccionario                       \n",
    "\n",
    "            # TU CÓDIGO AQUÍ (no borrar el 'pass' de debajo)\n",
    "            # ...    \n",
    "            # TU CÓDIGO AQUÍ (no borrar el 'pass' de debajo)\n",
    "            \n",
    "            pass\n",
    "            \n",
    "            \n",
    "  return\n",
    "            \n",
    "          \n",
    "\n",
    "# Abrimos fichero\n",
    "\n",
    "file_in = open(FICHERO, \"r\")\n",
    "\n",
    "# Diccionario para almacenar las frecuencias\n",
    "\n",
    "word_dictionary = {}\n",
    "\n",
    "# Lo recorremos línea a línea\n",
    "\n",
    "for line in file_in:\n",
    "  \n",
    "  # A minúsculas y quitamos el ruido del final de la cadena\n",
    "  \n",
    "  line = line.lower().rstrip()\n",
    "  \n",
    "  # Si la palabra existe en la línea\n",
    "  \n",
    "  if PALABRA in line:\n",
    "    \n",
    "    actualiza_diccionario(line, word_dictionary)\n",
    "                    \n",
    "# Cogemos las 50 palabras más frecuentes, ordenadas por conteo\n",
    "                \n",
    "frequent_words = sorted(word_dictionary.keys(), key=lambda key: word_dictionary[key], reverse=True)[:TOP_WORDS]\n",
    "\n",
    "# Imprimimos las palabras más frecuentes y su conteo\n",
    "\n",
    "for word in frequent_words:\n",
    "    text = word + \";\" + str(word_dictionary[word])\n",
    "    print(text)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Práctica final.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
